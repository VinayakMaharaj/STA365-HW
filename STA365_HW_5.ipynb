{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eP-v1IpfmTYG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "d37f12c7-50bd-4fef-fbeb-ea0017f827bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-14d878109d0a>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcategorical_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ever_married'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'work_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Residence_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'smoking_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Preparing the dataset for regression (Example: Predict 'bmi' based on other features excluding 'id' and 'stroke')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "import pymc as pm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming data loading and preprocessing have been done as previously discussed\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "# Encoding categorical variables using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
        "for col in categorical_columns:\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "\n",
        "# Preparing the dataset for regression (Example: Predict 'bmi' based on other features excluding 'id' and 'stroke')\n",
        "X = data.drop(columns=['id', 'bmi', 'stroke']).values\n",
        "y = data['bmi'].values.reshape(-1, 1)\n",
        "\n",
        "n, p = X.shape\n",
        "\n",
        "with pm.Model() as MLR:\n",
        "    # Priors for regression coefficients\n",
        "    betas = pm.MvNormal('betas', mu=np.zeros(p), cov=np.eye(p), shape=p)\n",
        "\n",
        "    # Experiment with different priors for sigma\n",
        "    # Option 1: Half-Normal\n",
        "    sigma_half_normal = pm.HalfNormal('sigma_half_normal', sigma=5)\n",
        "\n",
        "    # Option 2: Inverse-Gamma\n",
        "    alpha, beta = 3, 2  # Example hyperparameters\n",
        "    sigma_inverse_gamma = pm.InverseGamma('sigma_inverse_gamma', alpha=alpha, beta=beta)\n",
        "\n",
        "    # Option 3: Exponential\n",
        "    lambda_rate = 1\n",
        "    sigma_exponential = pm.Exponential('sigma_exponential', lam=lambda_rate)\n",
        "\n",
        "    # Option 4: Half-Cauchy\n",
        "    beta_cauchy = 5\n",
        "    sigma_half_cauchy = pm.HalfCauchy('sigma_half_cauchy', beta=beta_cauchy)\n",
        "\n",
        "    # Choose one of the sigma priors for the model (comment out others as needed)\n",
        "    sigma = sigma_half_normal  # Change this line to use different priors\n",
        "\n",
        "    # Linear model for the mean of the observed data\n",
        "    mu = pm.math.dot(X, betas)\n",
        "\n",
        "    # Likelihood of the observed data\n",
        "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y.ravel())\n",
        "\n",
        "    # Sampling from the posterior\n",
        "    idata = pm.sample(return_inferencedata=True, target_accept=0.95, chains=2, draws=1000)\n",
        "\n",
        "# After sampling, to view the summary of the posterior distributions for the parameters\n",
        "summary = pm.summary(idata)\n",
        "print(summary)\n",
        "\n",
        "# You might also generate posterior predictive checks\n",
        "with MLR:\n",
        "    ppc = pm.sample_posterior_predictive(idata)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the posterior distribution\n",
        "\\begin{align*}\n",
        "\\beta|\\Sigma, X, y\n",
        "\\end{align*}\n",
        "expressed in terms of the covariance matrix\n",
        "\\begin{align*}\n",
        "\\Sigma,\n",
        "\\end{align*}\n",
        "we can re-express it in terms of the variance\n",
        "\\begin{align*}\n",
        "\\sigma^2\n",
        "\\end{align*}\n",
        "by substituting  \n",
        "\\begin{align*}\n",
        "\\Sigma  \n",
        "\\end{align*}  \n",
        "with\n",
        "\\begin{align*}\n",
        "\\sigma^2I\n",
        "\\end{align*}\n",
        "where  \n",
        "\\begin{align*}\n",
        "\\sigma^2 = \\frac{1}{\\tau}.\n",
        "\\end{align*}\n",
        "This substitution reflects a simplifying assumption that the error variances are identical across all dimensions and independent, leading to a diagonal covariance matrix. Consequently, the inverse of the covariance matrix,\n",
        "\\begin{align*}\n",
        "\\Sigma^{-1},\n",
        "\\end{align*}\n",
        "becomes\n",
        "\\begin{align*}\n",
        "\\tau I,\n",
        "\\end{align*}\n",
        "where\n",
        "\\begin{align*}\n",
        "I\n",
        "\\end{align*}\n",
        "is the identity matrix and\n",
        "\\begin{align*}\n",
        "\\tau\n",
        "\\end{align*}\n",
        "is the precision, the reciprocal of the variance. The updated expressions for the expectation and variance of the posterior distribution of\n",
        "\\begin{align*}\n",
        "\\beta\n",
        "\\end{align*}\n",
        "are:\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[\\beta] &= (X^TX + \\tau I)^{-1}X^Ty \\\\\n",
        "\\text{Var}[\\beta] &= (X^TX + \\tau I)^{-1}\n",
        "\\end{align*}\n",
        "\n",
        "These equations represent the mean and variance of the posterior distribution for\n",
        "\\begin{align*}\n",
        "\\beta\n",
        "\\end{align*}\n",
        "in a Bayesian linear regression model, where the prior distribution of\n",
        "\\begin{align*}\n",
        "\\beta\n",
        "\\end{align*}\n",
        "is assumed to be multivariate normal with mean zero and variance\n",
        "\\begin{align*}\n",
        "\\sigma^2I.\n",
        "\\end{align*}\n"
      ],
      "metadata": {
        "id": "WBtXuPDtugr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align*}\n",
        "&\\text{The expected value of } \\beta \\text{ given the covariance matrix } \\Sigma, \\text{ the design matrix } X, \\text{ and the observed outcomes } y, \\text{ denoted as } \\mathbb{E}[\\beta|\\Sigma, X, y], \\text{ is calculated using the formula:} \\\\\n",
        "&\\mathbb{E}[\\beta|\\Sigma, X, y] = (X^TX + \\Sigma^{-1})^{-1}X^Ty\n",
        "\\end{align*}\n",
        "This represents the posterior mean of the regression coefficients in a Bayesian multivariate normal regression model, where $\\Sigma$ is the prior covariance matrix of the coefficients, $X$ is the matrix of predictors, and $y$ is the vector of observed responses. The term $(X^TX + \\Sigma^{-1})^{-1}$ is the precision matrix of the posterior distribution, and $X^Ty$ is the product of the transpose of $X$ and $y$.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GTQOLe1AvbgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the expectation $\\mathbb{E}[\\beta|\\Sigma, X, y]$ equal to $(X^TX)^{-1}X^Ty$, we would need $\\Sigma^{-1}$ to be the zero matrix. However, this is not possible because $\\Sigma$ is a covariance matrix and must be positive semi-definite, thus its inverse (if it exists) is positive definite and cannot be the zero matrix.\n",
        "\n",
        "The only scenario where $\\mathbb{E}[\\beta|\\Sigma, X, y]$ would equal $(X^TX)^{-1}X^Ty$ is in the limit as the prior variance goes to infinity, which reflects a non-informative prior for $\\beta$. This can be represented mathematically as:\n",
        "\n",
        "\\begin{align*}\n",
        "\\lim_{\\Sigma \\to \\infty} \\mathbb{E}[\\beta|\\Sigma, X, y] &= \\lim_{\\Sigma \\to \\infty} (X^TX + \\Sigma^{-1})^{-1}X^Ty \\\\\n",
        "&= (X^TX)^{-1}X^Ty\n",
        "\\end{align*}\n",
        "\n",
        "In practice, setting a very large value for the elements of $\\Sigma$ (or a very small value for elements of $\\Sigma^{-1}$) approximates this condition, but no finite value will exactly yield the ordinary least squares (OLS) estimator.\n"
      ],
      "metadata": {
        "id": "5HN-sbrHyZYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the expectation $\\mathbb{E}[\\beta|\\Sigma, X, y]$ to equal $(X^TX)^{-1}X^Ty$, we require that $\\Sigma^{-1}$, the precision matrix of the prior distribution, approaches the zero matrix. However, since $\\Sigma$ is a covariance matrix, it is by definition positive semi-definite, and its inverse is positive definite, thus it cannot be the zero matrix. The scenario where the expectation equals the ordinary least squares (OLS) estimator is in the limit as the prior variance goes to infinity. Mathematically, this is expressed as:\n",
        "\n",
        "\\begin{align*}\n",
        "\\lim_{\\Sigma \\to \\infty} \\mathbb{E}[\\beta|\\Sigma, X, y] &= \\lim_{\\Sigma \\to \\infty} (X^TX + \\Sigma^{-1})^{-1}X^Ty \\\\\n",
        "&= (X^TX)^{-1}X^Ty\n",
        "\\end{align*}\n",
        "\n",
        "This implies a non-informative prior for $\\beta$, where the prior variance is infinite and the prior's influence on the posterior is negligible.\n",
        "\n"
      ],
      "metadata": {
        "id": "zenoQa2jyedY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align*}\\text{Var}[\\beta|\\Sigma, X, y] = (X^TX + \\Sigma^{-1})^{-1}\\end{align*}\n"
      ],
      "metadata": {
        "id": "TF5FnQe9kYLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset (make sure to adjust the path to where the dataset is located on your machine)\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "\n",
        "# Drop 'id' as it is not a feature and fill missing 'bmi' values with the median\n",
        "data.drop(columns='id', inplace=True)\n",
        "data['bmi'].fillna(data['bmi'].median(), inplace=True)\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_features = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
        "for feature in categorical_features:\n",
        "    data[feature] = LabelEncoder().fit_transform(data[feature])\n",
        "\n",
        "# Define the feature matrix X and target vector y\n",
        "X = data.drop(columns='stroke').values  # assuming we want to predict the likelihood of stroke\n",
        "y = data['stroke'].values\n",
        "\n",
        "# Define the number of features\n",
        "p = X.shape[1]\n",
        "\n",
        "# Bayesian Multivariate Normal Model using PyMC\n",
        "with pm.Model() as MNV_LKJ:\n",
        "    # Define the packed L matrix for the Cholesky decomposition\n",
        "    packed_L = pm.LKJCholeskyCov('packed_L', n=p, eta=2.0, sd_dist=pm.Exponential.dist(1.0, shape=p), compute_corr=False)\n",
        "    # Unpack L to lower triangular matrix L\n",
        "    L = pm.expand_packed_triangular(p, packed_L)\n",
        "    # Define the mean vector for the multivariate normal distribution\n",
        "    mu = pm.Normal('mu', mu=np.zeros(p), sigma=1.0, shape=p)\n",
        "    # Define the observed data likelihood\n",
        "    y_obs = pm.MvNormal('y_obs', mu=mu, chol=L, observed=y)\n",
        "\n",
        "    # Perform sampling\n",
        "    trace = pm.sample(1000, return_inferencedata=True)\n",
        "\n",
        "# You can inspect the trace using trace.to_dataframe() in your local environment\n"
      ],
      "metadata": {
        "id": "0mL87JBFlLwm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "9cacbcf2-ba8e-407d-b9af-3d5414330f83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'healthcare-dataset-stroke-data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-086b2c63184b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the dataset (make sure to adjust the path to where the dataset is located on your machine)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'healthcare-dataset-stroke-data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Drop 'id' as it is not a feature and fill missing 'bmi' values with the median\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'healthcare-dataset-stroke-data.csv'"
          ]
        }
      ]
    }
  ]
}
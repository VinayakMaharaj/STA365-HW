{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Describe how the posterior predictive distribution is created for mixture models"
      ],
      "metadata": {
        "id": "1kenrR3g6AjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In mixture models, the posterior predictive distribution is calculated as follows:\n",
        "\n",
        "1. Parameter Estimation: Estimate the parameters of the mixture model, such as means, variances, and mixing coefficients.\n",
        "\n",
        "2. Posterior Distribution: Compute the posterior distribution of these parameters given the observed data, applying Bayes' theorem:\n",
        "\n",
        "$$\n",
        "p(\\theta | X) = \\frac{p(X | \\theta) p(\\theta)}{p(X)}\n",
        "$$\n",
        "\n",
        "where \\( \\theta \\) represents the parameters of the mixture model, \\( X \\) is the observed data, \\( p(X | \\theta) \\) is the likelihood of the data given the parameters, \\( p(\\theta) \\) is the prior, and \\( p(X) \\) is the evidence or marginal likelihood of the data.\n",
        "\n",
        "3. Predictive Distribution for New Data: Integrate over all possible values of the parameters to get the predictive distribution for a new data point \\( \\tilde{x} \\):\n",
        "\n",
        "$$\n",
        "p(\\tilde{x} | X) = \\int p(\\tilde{x} | \\theta) p(\\theta | X) d\\theta\n",
        "$$\n",
        "\n",
        "4. Account for Mixture Components: For each mixture component, calculate the likelihood of the new data point and take a weighted average according to the mixing coefficients.\n",
        "\n",
        "5. Sampling Methods: If the integral cannot be computed analytically, use sampling methods such as Markov Chain Monte Carlo (MCMC) to approximate the posterior predictive distribution.\n"
      ],
      "metadata": {
        "id": "vQS-dqtI6IOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Describe how the posterior predictive distribution is created in general"
      ],
      "metadata": {
        "id": "6cYVY8FI7DXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The posterior predictive distribution is created in the following general steps:\n",
        "\n",
        "1. Collect Data: Obtain the data set \\( X \\).\n",
        "\n",
        "2. Specify Prior Distribution: Choose a prior \\( p(\\theta) \\) for the parameters.\n",
        "\n",
        "3. Specify Likelihood Function: Define \\( p(X | \\theta) \\).\n",
        "\n",
        "4. Compute Posterior Distribution: Apply Bayes' theorem to get \\( p(\\theta | X) \\):\n",
        "\n",
        "$$\n",
        "p(\\theta | X) = \\frac{p(X | \\theta) p(\\theta)}{p(X)}\n",
        "$$\n",
        "\n",
        "5. Define Predictive Distribution: For a new observation \\( \\tilde{x} \\), compute:\n",
        "\n",
        "$$\n",
        "p(\\tilde{x} | X) = \\int p(\\tilde{x} | \\theta) p(\\theta | X) d\\theta\n",
        "$$\n",
        "\n",
        "6. Approximation Methods: Use MCMC or other numerical methods if the integral is intractable.\n"
      ],
      "metadata": {
        "id": "8HhthP8w6-Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3"
      ],
      "metadata": {
        "id": "xb0fy2CX7jzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When doing a regression of \\( y \\) on \\( X \\) with missing values in \\( X \\), Bayesian analysis can be performed without discarding the rows with missing data by treating the missing values as latent variables to be inferred. The process includes:\n",
        "\n",
        "1. Model the Missing Data: Treat the missing values as latent variables with a prior distribution.\n",
        "\n",
        "2. Specify a Joint Model: Create a joint model for both the observed and missing data.\n",
        "\n",
        "3. Infer Missing Data via Posterior: Use Bayesian inference to estimate the distribution of the missing data.\n",
        "\n",
        "4. Data Augmentation: Iteratively sample from the posterior distribution of the missing values and the model parameters using techniques like MCMC.\n",
        "\n",
        "5. Check MCAR Assumption: Ensure that the Missing Completely at Random assumption holds, or adjust the model to account for the missing data mechanism.\n",
        "\n",
        "This approach incorporates all available data and provides estimates for the missing values, potentially leading to better inference.\n"
      ],
      "metadata": {
        "id": "F-ddxJc-7nY5"
      }
    }
  ]
}
